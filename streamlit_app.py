import streamlit as st
import base64
import io
import re
import pandas as pd
from PIL import Image
from PyPDF2 import PdfReader
import regex as re
from presidio_analyzer import AnalyzerEngine, RecognizerRegistry, PatternRecognizer, Pattern, EntityRecognizer
from presidio_analyzer.nlp_engine import NlpEngineProvider
from presidio_anonymizer import AnonymizerEngine
from presidio_anonymizer.entities import OperatorConfig

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Anonimizador de Textos - LGPD",
    page_icon="üîí",
    layout="wide",
    initial_sidebar_state="auto",
)

def create_pt_br_recognizers():
    """
    Cria reconhecedores personalizados para o portugu√™s brasileiro
    """
    recognizers = []
    
    # CPF Recognizer
    cpf_pattern = Pattern(
        name="cpf_pattern",
        regex=r'\d{3}\.?\d{3}\.?\d{3}-?\d{2}',
        score=0.9
    )
    cpf_recognizer = PatternRecognizer(
        supported_entity="CPF",
        patterns=[cpf_pattern],
        context=["cpf", "cadastro de pessoa f√≠sica", "documento", "n√∫mero"]
    )
    recognizers.append(cpf_recognizer)
    
    # CNPJ Recognizer
    cnpj_pattern = Pattern(
        name="cnpj_pattern",
        regex=r'\d{2}\.?\d{3}\.?\d{3}/?\.?\d{4}-?\d{2}',
        score=0.9
    )
    cnpj_recognizer = PatternRecognizer(
        supported_entity="CNPJ",
        patterns=[cnpj_pattern],
        context=["cnpj", "cadastro nacional", "empresa", "pessoa jur√≠dica"]
    )
    recognizers.append(cnpj_recognizer)
    
    # RG Recognizer
    rg_pattern = Pattern(
        name="rg_pattern",
        regex=r'\d{1,2}\.?\d{3}\.?\d{3}-?[\dxX]',
        score=0.7
    )
    rg_recognizer = PatternRecognizer(
        supported_entity="RG", 
        patterns=[rg_pattern],
        context=["rg", "registro geral", "identidade", "documento"]
    )
    recognizers.append(rg_recognizer)
    
    # Telefone Brasileiro
    telefone_pattern = Pattern(
        name="telefone_pattern",
        regex=r'(\(?\d{2}\)?)\s*(\d{4,5})-?(\d{4})|\(\d{2}\)\s*\d{4,5}-?\d{4}|(\d{2})\s*9?\d{4}-?\d{4}',
        score=0.8
    )
    telefone_recognizer = PatternRecognizer(
        supported_entity="TELEFONE",
        patterns=[telefone_pattern],
        context=["telefone", "celular", "contato", "ligar", "whatsapp"]
    )
    recognizers.append(telefone_recognizer)
    
    # CEP Brasileiro
    cep_pattern = Pattern(
        name="cep_pattern",
        regex=r'\d{5}-?\d{3}',
        score=0.8
    )
    cep_recognizer = PatternRecognizer(
        supported_entity="CEP",
        patterns=[cep_pattern],
        context=["cep", "c√≥digo postal", "endere√ßo"]
    )
    recognizers.append(cep_recognizer)
    
    # Endere√ßo
    endereco_pattern = Pattern(
        name="endereco_pattern",
        regex=r'(rua|avenida|av\.|alameda|pra√ßa|travessa|rod\.|rodovia)\s+[A-Za-z√Ä-√ø\s\.\,0-9]+,?\s*(n¬∞\.?|n¬∫\.?|n√∫mero\.?)?\s*\d*',
        score=0.65
    )
    endereco_recognizer = PatternRecognizer(
        supported_entity="ENDERECO",
        patterns=[endereco_pattern],
        context=["endere√ßo", "localizado", "reside", "mora"]
    )
    recognizers.append(endereco_recognizer)
    
    # Cart√£o de Cr√©dito
    cartao_pattern = Pattern(
        name="cartao_pattern",
        regex=r'\d{4}[\s.-]?\d{4}[\s.-]?\d{4}[\s.-]?\d{4}',
        score=0.9
    )
    cartao_recognizer = PatternRecognizer(
        supported_entity="CARTAO_CREDITO",
        patterns=[cartao_pattern],
        context=["cart√£o", "cr√©dito", "d√©bito", "visa", "master"]
    )
    recognizers.append(cartao_recognizer)
    
    # Data de Nascimento
    data_pattern = Pattern(
        name="data_pattern",
        regex=r'nascido\s+em\s+\d{2}[./]\d{2}[./]\d{4}|nascida\s+em\s+\d{2}[./]\d{2}[./]\d{4}|data\s+de\s+nascimento:?\s+\d{2}[./]\d{2}[./]\d{4}',
        score=0.8
    )
    data_recognizer = PatternRecognizer(
        supported_entity="DATA_NASCIMENTO",
        patterns=[data_pattern],
        context=["nascimento", "nascido", "nascida", "idade"]
    )
    recognizers.append(data_recognizer)
    
    # Filia√ß√£o
    filiacao_pattern = Pattern(
        name="filiacao_pattern",
        regex=r'filho\s+(de|da|do)\s+[A-Za-z√Ä-√ø\s]+(\s+e\s+de\s+[A-Za-z√Ä-√ø\s]+)?',
        score=0.7
    )
    filiacao_recognizer = PatternRecognizer(
        supported_entity="FILIACAO",
        patterns=[filiacao_pattern],
        context=["filho", "filha", "pai", "m√£e", "genitores"]
    )
    recognizers.append(filiacao_recognizer)
    
    # Estado Civil
    estado_civil_pattern = Pattern(
        name="estado_civil_pattern",
        regex=r'estado\s+civil\s*:?\s*(casado|solteiro|vi√∫vo|divorciado|separado|uni√£o est√°vel)',
        score=0.7
    )
    estado_civil_recognizer = PatternRecognizer(
        supported_entity="ESTADO_CIVIL",
        patterns=[estado_civil_pattern],
        context=["estado civil", "casado", "solteiro", "vi√∫vo", "divorciado"]
    )
    recognizers.append(estado_civil_recognizer)
    
    # Idade
    idade_pattern = Pattern(
        name="idade_pattern",
        regex=r'\b\d{1,3}\s+anos\b|\bidade\s+de\s+\d{1,3}\b',
        score=0.6
    )
    idade_recognizer = PatternRecognizer(
        supported_entity="IDADE",
        patterns=[idade_pattern],
        context=["idade", "anos", "anivers√°rio"]
    )
    recognizers.append(idade_recognizer)
    
    # Profiss√£o
    profissao_pattern = Pattern(
        name="profissao_pattern",
        regex=r'profiss√£o\s*:?\s*[A-Za-z√Ä-√ø\s]+',
        score=0.6
    )
    profissao_recognizer = PatternRecognizer(
        supported_entity="PROFISSAO",
        patterns=[profissao_pattern],
        context=["trabalha", "emprego", "ocupa√ß√£o", "cargo"]
    )
    recognizers.append(profissao_recognizer)
    
    return recognizers

def create_custom_deny_list_recognizer(deny_list):
    """
    Cria um reconhecedor baseado em uma lista personalizada de palavras
    """
    if not deny_list or not any(deny_list):
        return None
        
    patterns = []
    for i, word in enumerate(deny_list):
        if word and len(word) > 2:  # Ignora palavras muito curtas
            word_pattern = Pattern(
                name=f"custom_pattern_{i}",
                regex=r'\b' + re.escape(word) + r'\b',
                score=0.7
            )
            patterns.append(word_pattern)
            
    if patterns:
        return PatternRecognizer(
            supported_entity="CUSTOM",
            patterns=patterns,
            context=[]
        )
    return None

def setup_analyzer_engine(deny_list=None):
    """
    Configura o motor de an√°lise do Presidio com os reconhecedores personalizados
    """
    # Criar um registro de reconhecedores
    registry = RecognizerRegistry(supported_languages=["pt"])
    
    # Configurar o provedor de NLP
    nlp_engine = NlpEngineProvider(nlp_configuration={
        "nlp_engine_name": "spacy",
        "models": [{"lang_code": "pt", "model_name": "pt_core_news_md"}]
    }).create_engine()
    
    # Adicionar os reconhecedores padr√£o da Presidio com suporte a PT
    registry.load_predefined_recognizers(languages=["pt"])
    
    # Adicionar os reconhecedores personalizados
    for recognizer in create_pt_br_recognizers():
        registry.add_recognizer(recognizer)
    
    # Adicionar o reconhecedor personalizado de lista negada
    if deny_list:
        custom_deny_list_recognizer = create_custom_deny_list_recognizer(deny_list)
        if custom_deny_list_recognizer:
            registry.add_recognizer(custom_deny_list_recognizer)
    
    # Criar o motor de an√°lise
    analyzer = AnalyzerEngine(
        registry=registry,
        nlp_engine=nlp_engine,
        supported_languages=["pt"]
    )
    
    return analyzer

def setup_anonymizer_engine():
    """
    Configura o motor de anonimiza√ß√£o do Presidio
    """
    return AnonymizerEngine()

def anonimizar_com_presidio(texto, deny_list=None, mascara='*'):
    """
    Anonimiza o texto usando o Presidio
    """
    if not texto:
        return texto, []
    
    # Configurar o motor de an√°lise
    analyzer = setup_analyzer_engine(deny_list)
    
    # Configurar o motor de anonimiza√ß√£o
    anonymizer = setup_anonymizer_engine()
    
    # Analisar o texto
    results = analyzer.analyze(
        text=texto,
        language="pt",
        entities=None,  # Detectar todas as entidades suportadas
        allow_list=None,
        score_threshold=0.4  # Ajustar conforme necess√°rio
    )
    
    # Configurar opera√ß√µes de anonimiza√ß√£o
    operators = {
        "DEFAULT": OperatorConfig("replace", {"new_value": mascara * 5}),
        "PHONE_NUMBER": OperatorConfig("mask", {"masking_char": mascara, "chars_to_mask": 10, "from_end": False}),
        "CREDIT_CARD": OperatorConfig("mask", {"masking_char": mascara, "chars_to_mask": 12, "from_end": True}),
        "CUSTOM": OperatorConfig("replace", {"new_value": mascara * 7}),
    }
    
    # Converter os resultados do Presidio para o formato esperado pelo c√≥digo original
    achados = []
    for result in results:
        achados.append({
            'Tipo de Entidade': result.entity_type,
            'Texto': texto[result.start:result.end],
            'In√≠cio': result.start,
            'Fim': result.end,
            'Confian√ßa': result.score
        })
    
    # Anonimizar o texto se houver achados
    if results:
        try:
            anonymized_result = anonymizer.anonymize(
                text=texto,
                analyzer_results=results,
                operators=operators
            )
            texto_anonimizado = anonymized_result.text
        except Exception as e:
            st.error(f"Erro na anonimiza√ß√£o: {str(e)}")
            # Fallback para m√©todo mais simples se o anonymizer falhar
            texto_anonimizado = texto
            for result in results:
                texto_anonimizado = texto_anonimizado.replace(
                    texto[result.start:result.end],
                    mascara * len(texto[result.start:result.end])
                )
    else:
        texto_anonimizado = texto
    
    return texto_anonimizado, achados

def anonimizar_hibrido(texto, palavras_adicionais=None, mascara='*', tolerancia=0.5):
    """
    Fun√ß√£o h√≠brida que combina o Presidio com o m√©todo simples para melhor cobertura
    """
    if not texto:
        return texto, []
    
    # Lista para armazenar palavras adicionais
    deny_list = [p.strip() for p in palavras_adicionais.split(",")] if palavras_adicionais else []
    
    # Primeiro, usar Presidio para anonimiza√ß√£o
    texto_presidio, achados_presidio = anonimizar_com_presidio(texto, deny_list, mascara)
    
    # Se o Presidio n√£o encontrou nada ou encontrou poucos dados, tentar o m√©todo simples como backup
    if len(achados_presidio) < 3:  # N√∫mero arbitr√°rio para decidir se vale a pena tentar o m√©todo simples
        texto_simples, achados_simples = anonimizar_simples(texto, deny_list, mascara)
        
        # Comparar resultados e escolher o que encontrou mais achados
        if len(achados_simples) > len(achados_presidio):
            return texto_simples, achados_simples
    
    return texto_presidio, achados_presidio

# Fun√ß√£o anonimizar_simples mantida para backup
def anonimizar_simples(texto, palavras_adicionais=None, mascara='*'):
    """
    Fun√ß√£o de anonimiza√ß√£o simples usando express√µes regulares
    """
    if not texto:
        return texto, []
    
    # Lista para armazenar os achados
    achados = []
    texto_original = texto
    
    # Fun√ß√£o auxiliar para substituir mantendo o case original
    def substituir_preservando_maiusculas(match):
        trecho = match.group(0)
        return mascara * len(trecho)
        
    # Lista de termos sens√≠veis a serem sempre anonimizados
    termos_sensiveis = [
        # Ra√ßa e etnia
        "Ra√ßa", "etnia", "cor da pele", "origem racial", "afrodescendente", 
        "ind√≠gena", "branco", "negro", "pardo", "amarelo", "ascend√™ncia", 
        "nacionalidade",
        
        # Religi√£o
        "religi√£o", "cren√ßa", "f√©", "igreja", "templo", "culto", "cat√≥lico", 
        "evang√©lico", "protestante", "esp√≠rita", "candombl√©", "umbanda", "ateu", 
        "agn√≥stico", "juda√≠smo", "islamismo", "budismo",
        
        # Opini√£o pol√≠tica
        "opini√£o pol√≠tica", "partido pol√≠tico", "filia√ß√£o partid√°ria", "esquerda", 
        "direita", "centro", "conservador", "progressista", "liberal", "sindicalista", 
        "sindicato", "filia√ß√£o sindical", "sindicalizado",
        
        # Orienta√ß√£o sexual
        "orienta√ß√£o sexual", "heterossexual", "homossexual", "bissexual", "gay", 
        "l√©sbica", "transg√™nero", "LGBTQIA+", "vida sexual", "pr√°ticas sexuais",
        
        # Estado civil
        "casado", "solteiro", "vi√∫vo", "vi√∫va", "casada", "divorciado", "divorciada",
        "separado", "separada", "uni√£o est√°vel",
        
        # Profiss√£o
        "advogado", "m√©dico", "m√©dica", "engenheiro", "engenheira", "professor", "professora",
        "contador", "contadora", "dentista", "enfermeiro", "enfermeira", "arquiteto", "arquiteta",
        "policial", "motorista", "vendedor", "vendedora", "empres√°rio", "empres√°ria", "aut√¥nomo",
        "aut√¥noma", "desempregado", "desempregada", "aposentado", "aposentada", "estudante",
        "estagi√°rio", "estagi√°ria", "funcion√°rio p√∫blico", "funcion√°ria p√∫blica",
        
        # Filia√ß√£o
        "filho de", "filha de", "pai", "m√£e", "filia√ß√£o", "filho", "filha", "genitor", "genitora",
        
        # Sa√∫de
        "sa√∫de", "prontu√°rio m√©dico", "doen√ßa", "enfermidade", "diagn√≥stico", 
        "tratamento m√©dico", "medicamento", "condi√ß√£o de sa√∫de", "defici√™ncia", 
        "transtorno", "hist√≥rico m√©dico", "exame", "resultado de exame", "interna√ß√£o", 
        "cirurgia", "HIV", "AIDS", "c√¢ncer", "diabetes", "hipertens√£o",
        
        # Dados gen√©ticos e biom√©tricos
        "dados gen√©ticos", "DNA", "genoma", "c√≥digo gen√©tico", "material gen√©tico", 
        "dados biom√©tricos", "impress√£o digital", "reconhecimento facial", "√≠ris", 
        "retina", "voz", "assinatura", "marcha",
        
        # Antecedentes criminais
        "antecedentes criminais", "processo criminal", "hist√≥rico judicial", 
        "condena√ß√£o", "delito", "crime", "contraven√ß√£o",
        
        # Outros dados sens√≠veis
        "biometria", "senhas", "geolocaliza√ß√£o", "endere√ßo IP", 
        "identificadores digitais"
    ]
    
    # Padr√µes para identificar informa√ß√µes pessoais
    padroes = {
        'CPF': r'\d{3}\.?\d{3}\.?\d{3}-?\d{2}',
        'CNPJ': r'\d{2}\.?\d{3}\.?\d{3}/?\.?\d{4}-?\d{2}',
        'RG': r'\d{1,2}\.?\d{3}\.?\d{3}-?[\dxX]',
        'TELEFONE': r'(\(?\d{2}\)?)\s*(\d{4,5})-?(\d{4})|\(\d{2}\)\s*\d{4,5}-?\d{4}|(\d{2})\s*9?\d{4}-?\d{4}',
        'CEP': r'\d{5}-?\d{3}',
        'EMAIL': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b|[Ee]-?mail:?\s*[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}',
        'CARTAO_CREDITO': r'\d{4}[\s.-]?\d{4}[\s.-]?\d{4}[\s.-]?\d{4}',
        'DATA': r'\d{2}[./]\d{2}[./]\d{4}|\d{2}-\d{2}-\d{4}',
        'NOME_EMPRESA': r'([A-Z][A-Z√Ä-√ö]+\s+){2,}([A-Z][A-Z√Ä-√ö\s]*)+', # Sequ√™ncia de palavras em mai√∫sculas
        'IDADE': r'\b\d{1,3}\s+anos\b|\bidade\s+de\s+\d{1,3}\b',
        'DATA_NASCIMENTO': r'nascido\s+em\s+\d{2}[./]\d{2}[./]\d{4}|nascida\s+em\s+\d{2}[./]\d{2}[./]\d{4}|data\s+de\s+nascimento:?\s+\d{2}[./]\d{2}[./]\d{4}',
        'ENDERECO': r'residente\s+(e\s+domiciliado\s+)?(a|√†|na|no)?\s+.{5,50}(,\s+n¬∞\.?\s+\d+)?|morador\s+(a|√†|na|no)?\s+.{5,50}(,\s+n¬∞\.?\s+\d+)?',
        'ENDERECO_RUA': r'(rua|avenida|av\.|alameda|pra√ßa|travessa|rod\.|rodovia)\s+[A-Za-z√Ä-√ø\s\.\,0-9]+,?\s*(n¬∞\.?|n¬∫\.?|n√∫mero\.?)?\s*\d*',
        'ENDERECO_BAIRRO': r'(bairro|b\.)\s+[A-Za-z√Ä-√ø\s]+',
        'ENDERECO_CIDADE': r'(cidade|cid\.|munic√≠pio) de\s+[A-Za-z√Ä-√ø\s]+|[Ee]m\s+[A-Z][a-z√Ä-√ø]+(/[A-Z]{2})?',
        'ESTADO_CIVIL': r'estado\s+civil\s*:?\s*(casado|solteiro|vi√∫vo|divorciado|separado|uni√£o est√°vel)',
        'PROFISSAO': r'profiss√£o\s*:?\s*[A-Za-z√Ä-√ø\s]+',
        'FILIACAO': r'filho\s+(de|da|do)\s+[A-Za-z√Ä-√ø\s]+(\s+e\s+de\s+[A-Za-z√Ä-√ø\s]+)?',
    }
    
    # Procurar e substituir os padr√µes
    for tipo, padrao in padroes.items():
        # Tratamento especial para nomes de empresas em mai√∫sculas
        if tipo == 'NOME_EMPRESA':
            # Usamos re.UNICODE para suportar caracteres acentuados
            for match in re.finditer(padrao, texto, re.UNICODE):
                info = match.group()
                # Verificar se tem pelo menos 3 palavras ou no m√≠nimo 10 caracteres (para empresas com 2 palavras mais longas)
                palavras = [p for p in info.split() if p.strip()]
                if len(palavras) >= 2 and len(info) >= 10:
                    start = match.start()
                    end = match.end()
                    
                    # Armazenar o achado
                    achados.append({
                        'Tipo de Entidade': tipo,
                        'Texto': info,
                        'In√≠cio': start,
                        'Fim': end,
                        'Confian√ßa': 0.95
                    })
                    
                    # Substituir a informa√ß√£o por asteriscos
                    mascara_texto = mascara * len(info)
                    texto = texto.replace(info, mascara_texto)
        # Tratamento especial para endere√ßos e outros padr√µes longos
        elif tipo in ['ENDERECO', 'ENDERECO_RUA', 'PROFISSAO', 'FILIACAO']:
            for match in re.finditer(padrao, texto, re.IGNORECASE):
                info = match.group()
                start = match.start()
                end = match.end()
                
                # Armazenar o achado
                achados.append({
                    'Tipo de Entidade': tipo,
                    'Texto': info,
                    'In√≠cio': start,
                    'Fim': end,
                    'Confian√ßa': 0.9
                })
                
                # Substituir a informa√ß√£o por asteriscos
                mascara_texto = mascara * len(info)
                texto = texto.replace(info, mascara_texto)
        else:
            for match in re.finditer(padrao, texto, re.IGNORECASE):
                info = match.group()
                start = match.start()
                end = match.end()
                
                # Armazenar o achado
                achados.append({
                    'Tipo de Entidade': tipo,
                    'Texto': info,
                    'In√≠cio': start,
                    'Fim': end,
                    'Confian√ßa': 1.0
                })
                
                # Substituir a informa√ß√£o por asteriscos
                mascara_texto = mascara * len(info)
                texto = texto.replace(info, mascara_texto)
    
    # Procurar e substituir nomes comuns brasileiros
    nomes_comuns = [
        "Silva", "Santos", "Oliveira", "Souza", "Lima", "Pereira", "Ferreira", 
        "Almeida", "Costa", "Rodrigues", "Gomes", "Martins", "Ara√∫jo", "Carvalho",
        "Jo√£o", "Jos√©", "Antonio", "Carlos", "Paulo", "Pedro", "Lucas", "Marcos", "Luis",
        "Gabriel", "Rafael", "Daniel", "Marcelo", "Bruno", "Eduardo", "Felipe", "Raimundo",
        "Maria", "Ana", "Francisca", "Antonia", "Adriana", "Juliana", "Marcia", "Fernanda",
        "Patricia", "Aline", "Sandra", "Camila", "Amanda", "Bruna", "Jessica", "Leticia"
    ]
    
    for nome in nomes_comuns:
        # Usando regex para encontrar nomes como palavras inteiras (n√£o parte de outras palavras)
        padrao_nome = r'\b' + re.escape(nome) + r'\b'
        for match in re.finditer(padrao_nome, texto, re.IGNORECASE):
            info = match.group()
            start = match.start()
            end = match.end()
            
            # Armazenar o achado
            achados.append({
                'Tipo de Entidade': 'NOME',
                'Texto': info,
                'In√≠cio': start,
                'Fim': end,
                'Confian√ßa': 0.85
            })
            
            # Substituir a informa√ß√£o por asteriscos
            mascara_texto = mascara * len(info)
            texto = texto.replace(info, mascara_texto)
    
    # Ap√≥s os reconhecedores padr√£o, aplicar os termos sens√≠veis
    for termo in termos_sensiveis:
        padrao_termo = r'\b' + re.escape(termo) + r'\b'
        for match in re.finditer(padrao_termo, texto, re.IGNORECASE):
            info = match.group()
            start = match.start()
            end = match.end()
            
            # Armazenar o achado
            achados.append({
                'Tipo de Entidade': 'TERMO_SENS√çVEL',
                'Texto': info,
                'In√≠cio': start,
                'Fim': end,
                'Confian√ßa': 0.90
            })
            
            # Substituir a informa√ß√£o por asteriscos
            mascara_texto = mascara * len(info)
            texto = texto.replace(info, mascara_texto)
    
    # Adicionar palavras personalizadas
    if palavras_adicionais:
        for palavra in palavras_adicionais:
            if palavra and len(palavra) > 2:  # Evitar palavras muito curtas
                padrao_palavra = r'\b' + re.escape(palavra) + r'\b'
                for match in re.finditer(padrao_palavra, texto, re.IGNORECASE):
                    info = match.group()
                    start = match.start()
                    end = match.end()
                    
                    # Armazenar o achado
                    achados.append({
                        'Tipo de Entidade': 'PERSONALIZADO',
                        'Texto': info,
                        'In√≠cio': start,
                        'Fim': end,
                        'Confian√ßa': 0.95
                    })
                    
                    # Substituir a informa√ß√£o por asteriscos
                    mascara_texto = mascara * len(info)
                    texto = texto.replace(info, mascara_texto)
    
    return texto, achados

def extract_text_from_pdf(pdf_file):
    """Extrai texto de um arquivo PDF"""
    try:
        reader = PdfReader(pdf_file)
        texto = ""
        for page in reader.pages:
            texto += page.extract_text() + "\n"
        return texto
    except Exception as e:
        st.error(f"Erro ao extrair texto do PDF: {str(e)}")
        return ""

def extract_text_from_csv(csv_file):
    """Extrai texto de um arquivo CSV"""
    try:
        df = pd.read_csv(csv_file)
        return df.to_string()
    except:
        try:
            df = pd.read_csv(csv_file, encoding='latin-1')
            return df.to_string()
        except Exception as e:
            st.error(f"Erro ao ler CSV: {str(e)}")
            return ""

def process_file(uploaded_file, tolerancia, palavras, mascara):
    """Processa um arquivo enviado pelo usu√°rio"""
    if uploaded_file.type == "application/pdf" or ".pdf" in uploaded_file.name.lower():
        texto = extract_text_from_pdf(uploaded_file)
    elif uploaded_file.type == "text/csv" or ".csv" in uploaded_file.name.lower():
        texto = extract_text_from_csv(uploaded_file)
    else:
        st.error("Tipo de arquivo n√£o suportado")
        return None
    
    if not texto:
        st.error("N√£o foi poss√≠vel extrair texto do arquivo.")
        return None
    
    return process_text(texto, tolerancia, palavras, mascara)

def process_text(texto, tolerancia, palavras, mascara):
    """Processa um texto para anonimiza√ß√£o, usando uma abordagem h√≠brida (Presidio + Regex)"""
    try:
        # Verifica o modo de anonimiza√ß√£o selecionado
        modo = st.session_state.get("modo_anonimizacao", "Autom√°tico (recomendado)")
        
        # Prepara a lista de palavras a serem negadas
        deny_list = [p.strip() for p in palavras.split(",")] if palavras else []
        
        # Escolhe a fun√ß√£o de anonimiza√ß√£o com base no modo selecionado
        if modo == "Presidio":
            texto_anonimizado, achados = anonimizar_com_presidio(texto, deny_list, mascara)
        elif modo == "Regex":
            texto_anonimizado, achados = anonimizar_simples(texto, deny_list, mascara)
        else:  # Autom√°tico
            texto_anonimizado, achados = anonimizar_hibrido(texto, palavras, mascara, tolerancia)
        
        # Se n√£o encontrou nada para anonimizar
        if not achados:
            # Retorna o texto original com uma nota
            return {
                "texto": texto,
                "findings": [],
                "message": "Nenhuma informa√ß√£o pessoal foi identificada no texto."
            }
        
        # Prepara a resposta
        response = {
            "texto": texto_anonimizado,
            "findings": achados
        }
        
        return response
        
    except Exception as e:
        st.error(f"Erro ao anonimizar texto: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return None

def main():
    st.title("Anonimizador de Textos - LGPD")
    st.markdown("""
    ### Proteja dados sens√≠veis de acordo com a Lei Geral de Prote√ß√£o de Dados
    Esta ferramenta ajuda a identificar e mascarar informa√ß√µes pessoais identific√°veis (PII) em textos, 
    utilizando a biblioteca Microsoft Presidio e t√©cnicas avan√ßadas de reconhecimento de padr√µes para o portugu√™s brasileiro.
    """)
    
    # Op√ß√µes de configura√ß√£o
    with st.expander("Configura√ß√µes de Anonimiza√ß√£o", expanded=True):
        col1, col2, col3 = st.columns(3)
        with col1:
            tolerancia = st.slider(
                "Toler√¢ncia de detec√ß√£o", 
                min_value=0.1, 
                max_value=1.0, 
                value=0.4,
                help="Valores menores detectam mais padr√µes, mas podem gerar falsos positivos"
            )
        with col2:
            palavras = st.text_input(
                "Palavras adicionais a mascarar", 
                placeholder="Palavras separadas por v√≠rgula (sem espa√ßos)",
                help="Lista de palavras espec√≠ficas que devem ser detectadas"
            )
        with col3:
            mascara = st.text_input(
                "Caractere de m√°scara",
                value="*",
                max_chars=1,
                help="Caractere usado para substituir informa√ß√µes pessoais"
            )
            
        # Modo de anonimiza√ß√£o
        st.radio(
            "Modo de anonimiza√ß√£o",
            ["Autom√°tico (recomendado)", "Presidio", "Regex"],
            index=0,
            key="modo_anonimizacao",
            help="Escolha o m√©todo de detec√ß√£o de informa√ß√µes pessoais. O modo Autom√°tico combina ambas as t√©cnicas."
        )
    
    # Cria√ß√£o de abas para os diferentes m√©todos de input
    tab1, tab2 = st.tabs(["Texto", "Arquivo (PDF/CSV)"])
    
    with tab1:
        st.subheader("Anonimiza√ß√£o de Texto")
        user_input = st.text_area(
            "Digite ou cole o texto:", 
            height=200,
            placeholder="Cole aqui o texto que deseja anonimizar...",
        )
        
        if st.button("Anonimizar Texto", type="primary", key="btn_texto"):
            if user_input:
                with st.spinner("Processando texto..."):
                    resultado = process_text(user_input, tolerancia, palavras, mascara)
                    if resultado:
                        if "message" in resultado:
                            st.info(resultado["message"])
                        else:
                            st.success("Texto anonimizado com sucesso!")
                        
                        # Display the findings
                        if "findings" in resultado and resultado["findings"]:
                            with st.expander("Informa√ß√µes detectadas", expanded=True):
                                findings_df = pd.DataFrame(resultado["findings"])
                                # Ordenar por confian√ßa (decrescente)
                                findings_df = findings_df.sort_values(by='Confian√ßa', ascending=False)
                                st.dataframe(findings_df)
                                
                                # M√©tricas de resumo
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("Total de itens identificados", len(findings_df))
                                with col2:
                                    num_tipos = findings_df['Tipo de Entidade'].nunique()
                                    st.metric("Tipos de dados diferentes", num_tipos)
                                with col3:
                                    confianca_media = findings_df['Confian√ßa'].mean()
                                    st.metric("Confian√ßa m√©dia", f"{confianca_media:.2f}")
                        
                        # Display the anonymized text
                        st.subheader("Resultado:")
                        st.markdown(
                            f"""<div style="padding: 15px; border-radius: 5px; background-color: #f0f2f6;">
                            {resultado["texto"]}
                            </div>""", 
                            unsafe_allow_html=True
                        )
                        
                        # Download option
                        text_download = resultado["texto"]
                        st.download_button(
                            label="Baixar texto anonimizado",
                            data=text_download,
                            file_name="texto_anonimizado.txt",
                            mime="text/plain"
                        )
                        
                        # Op√ß√£o para relat√≥rio
                        if "findings" in resultado and resultado["findings"]:
                            report = generate_anonymization_report(user_input, resultado)
                            st.download_button(
                                label="Baixar relat√≥rio detalhado",
                                data=report,
                                file_name="relatorio_anonimizacao.txt",
                                mime="text/plain"
                            )
            else:
                st.warning("Por favor, insira um texto para anonimizar.")
    
    with tab2:
        st.subheader("Anonimiza√ß√£o de Arquivo")
        uploaded_file = st.file_uploader("Fa√ßa upload do arquivo:", type=["pdf", "csv"])
        
        if uploaded_file is not None:
            file_details = {"Nome": uploaded_file.name, "Tipo": uploaded_file.type, "Tamanho": f"{uploaded_file.size/1024:.2f} KB"}
            st.write(file_details)
            
            if st.button("Anonimizar Arquivo", type="primary", key="btn_arquivo"):
                with st.spinner(f"Processando arquivo {uploaded_file.name}..."):
                    resultado = process_file(uploaded_file, tolerancia, palavras, mascara)
                    if resultado:
                        if "message" in resultado:
                            st.info(resultado["message"])
                        else:
                            st.success("Arquivo anonimizado com sucesso!")
                        
                        # Display the findings
                        if "findings" in resultado and resultado["findings"]:
                            with st.expander("Informa√ß√µes detectadas", expanded=True):
                                findings_df = pd.DataFrame(resultado["findings"])
                                # Ordenar por confian√ßa (decrescente)
                                findings_df = findings_df.sort_values(by='Confian√ßa', ascending=False)
                                st.dataframe(findings_df)
                                
                                # M√©tricas de resumo
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("Total de itens identificados", len(findings_df))
                                with col2:
                                    num_tipos = findings_df['Tipo de Entidade'].nunique()
                                    st.metric("Tipos de dados diferentes", num_tipos)
                                with col3:
                                    confianca_media = findings_df['Confian√ßa'].mean()
                                    st.metric("Confian√ßa m√©dia", f"{confianca_media:.2f}")
                        
                        # Display the anonymized text
                        st.subheader("Resultado:")
                        st.text_area("Texto anonimizado", value=resultado["texto"], height=400)
                        
                        # Download option
                        text_download = resultado["texto"]
                        st.download_button(
                            label="Baixar texto anonimizado",
                            data=text_download,
                            file_name=f"{uploaded_file.name}_anonimizado.txt",
                            mime="text/plain"
                        )
                        
                        # Op√ß√£o para relat√≥rio
                        if "findings" in resultado and resultado["findings"]:
                            report = generate_anonymization_report(
                                f"Arquivo: {uploaded_file.name}", 
                                resultado
                            )
                            st.download_button(
                                label="Baixar relat√≥rio detalhado",
                                data=report,
                                file_name=f"{uploaded_file.name}_relatorio.txt",
                                mime="text/plain"
                            )

    # Informa√ß√µes adicionais
    with st.expander("Sobre este anonimizador"):
        st.markdown("""
        ### Sobre o Anonimizador de Textos
        
        **Objetivos:**
        - Fornecer uma forma simples de preservar a privacidade de dados pessoais
        - Permitir customiza√ß√£o para atender a necessidades espec√≠ficas
        - Facilitar a detec√ß√£o autom√°tica e semi-autom√°tica de Informa√ß√µes Pessoais Identific√°veis (PII)
        - Atender √†s exig√™ncias da LGPD (Lei Geral de Prote√ß√£o de Dados Pessoais)
        
        **Tecnologias utilizadas:**
        - Microsoft Presidio: Framework de c√≥digo aberto para anonimiza√ß√£o de dados
        - Reconhecimento de Entidades Nomeadas (NER)
        - Express√µes regulares otimizadas para o portugu√™s brasileiro
        - Abordagem h√≠brida para maximizar a detec√ß√£o de dados pessoais
        
        **Limita√ß√µes:**
        > ‚ö†Ô∏è **Aten√ß√£o:** O anonimizador pode ajudar a identificar dados sens√≠veis em textos, mas por ser um 
        > mecanismo de detec√ß√£o autom√°tica, n√£o h√° garantias de que todas as informa√ß√µes sens√≠veis ser√£o encontradas.
        > Sistemas adicionais de prote√ß√£o devem ser empregados.
        > Sempre revise o texto anonimizado manualmente antes de us√°-lo em produ√ß√£o.
        
        **Tipos de dados detectados:**
        - CPF/CNPJ
        - RG
        - Endere√ßo completo e partes (rua, bairro, cidade)
        - Estado civil
        - Profiss√£o
        - Filia√ß√£o
        - Data de nascimento
        - Idade
        - Nomes comuns brasileiros
        - Nomes de empresas e organiza√ß√µes
        - CEPs
        - N√∫meros de telefone
        - E-mails
        - Dados de cart√£o de cr√©dito
        - Datas
        - Termos sens√≠veis (ra√ßa, religi√£o, orienta√ß√£o sexual, sa√∫de, dados biom√©tricos, etc.)
        - Palavras personalizadas definidas pelo usu√°rio
        
        **Conformidade com a LGPD:**
        Esta ferramenta ajuda a implementar medidas t√©cnicas para prote√ß√£o de dados pessoais,
        conforme requerido pelos artigos 46-49 da LGPD (Lei 13.709/2018), contribuindo para
        a minimiza√ß√£o de riscos e o tratamento adequado de dados sens√≠veis.
        """)
    
    # Rodap√©
    st.markdown("---")
    st.markdown("¬© 2025 Anonimizador de Textos - LGPD | Desenvolvido com Streamlit e Microsoft Presidio")

def generate_anonymization_report(original_text, resultado):
    """Gera um relat√≥rio detalhado da anonimiza√ß√£o"""
    findings = resultado.get("findings", [])
    texto_anonimizado = resultado.get("texto", "")
    
    report = "RELAT√ìRIO DE ANONIMIZA√á√ÉO DE DADOS\n"
    report += "=" * 50 + "\n\n"
    
    # Data e hora
    from datetime import datetime
    report += f"Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n\n"
    
    # Resumo
    report += "RESUMO:\n"
    report += "-" * 50 + "\n"
    report += f"Total de informa√ß√µes sens√≠veis encontradas: {len(findings)}\n"
    
    if findings:
        # Contar tipos de entidades
        tipos_entidade = {}
        for finding in findings:
            tipo = finding.get('Tipo de Entidade', 'Desconhecido')
            tipos_entidade[tipo] = tipos_entidade.get(tipo, 0) + 1
        
        report += "Distribui√ß√£o por tipo:\n"
        for tipo, contagem in tipos_entidade.items():
            report += f"  - {tipo}: {contagem}\n"
        
        # Confian√ßa m√©dia
        confianca_total = sum(finding.get('Confian√ßa', 0) for finding in findings)
        confianca_media = confianca_total / len(findings)
        report += f"Confian√ßa m√©dia: {confianca_media:.2f}\n\n"
        
        # Detalhes das informa√ß√µes encontradas
        report += "DETALHES DAS INFORMA√á√ïES ENCONTRADAS:\n"
        report += "-" * 50 + "\n"
        
        for i, finding in enumerate(findings, 1):
            report += f"Item {i}:\n"
            report += f"  Tipo: {finding.get('Tipo de Entidade', 'Desconhecido')}\n"
            report += f"  Texto: {finding.get('Texto', '')}\n"
            report += f"  Confian√ßa: {finding.get('Confian√ßa', 0):.2f}\n"
            report += f"  Posi√ß√£o: {finding.get('In√≠cio', 0)}-{finding.get('Fim', 0)}\n"
            report += "\n"
    
    # Amostras de texto (original e anonimizado)
    # Limitando para evitar relat√≥rios muito grandes
    max_sample_length = 1000
    sample_original = original_text[:max_sample_length] + ("..." if len(original_text) > max_sample_length else "")
    sample_anon = texto_anonimizado[:max_sample_length] + ("..." if len(texto_anonimizado) > max_sample_length else "")
    
    report += "AMOSTRA DE TEXTO ORIGINAL:\n"
    report += "-" * 50 + "\n"
    report += sample_original + "\n\n"
    
    report += "AMOSTRA DE TEXTO ANONIMIZADO:\n"
    report += "-" * 50 + "\n"
    report += sample_anon + "\n\n"
    
    # Recomenda√ß√µes
    report += "RECOMENDA√á√ïES:\n"
    report += "-" * 50 + "\n"
    report += "1. Verifique manualmente o texto anonimizado para garantir que todas as informa√ß√µes sens√≠veis foram detectadas.\n"
    report += "2. Considere ajustar a toler√¢ncia de detec√ß√£o se informa√ß√µes importantes n√£o foram identificadas.\n"
    report += "3. Para casos espec√≠ficos, adicione palavras personalizadas √† lista de detec√ß√£o.\n"
    report += "4. Lembre-se que esta √© uma ferramenta de aux√≠lio e n√£o substitui uma revis√£o manual cuidadosa.\n\n"
    
    report += "=" * 50 + "\n"
    report += "Este relat√≥rio foi gerado automaticamente pelo Anonimizador de Textos - LGPD.\n"
    
    return report

if __name__ == "__main__":
    main()
